{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fc718d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:11.299485Z",
     "start_time": "2021-11-08T01:46:11.296910Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85510ff",
   "metadata": {},
   "source": [
    "## 加载配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2208b7ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:11.305879Z",
     "start_time": "2021-11-08T01:46:11.301472Z"
    }
   },
   "outputs": [],
   "source": [
    "from yolo.cfg import read_json, Cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f53a32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:11.315704Z",
     "start_time": "2021-11-08T01:46:11.307654Z"
    }
   },
   "outputs": [],
   "source": [
    "if sys.argv[-1].startswith('cfg') and sys.argv[-1].endswith('.json'):\n",
    "    _cfg_path = 'cfg/' + sys.argv[-1]\n",
    "else:\n",
    "    _cfg_path = 'cfg/cfg-coco-anchor-B5-res18.json'\n",
    "\n",
    "print('load cfg from: ' + _cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edf300d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:11.325078Z",
     "start_time": "2021-11-08T01:46:11.317541Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg = Cfg(read_json(['cfg/cfg-default.json', _cfg_path]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875c16d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:11.335774Z",
     "start_time": "2021-11-08T01:46:11.327107Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.anchor.wh is None:\n",
    "    cfg.anchor['wh'] = cfg.anchor[cfg.base.dataset]\n",
    "    \n",
    "if not cfg.train.train:\n",
    "    # 没有开启训练，则就计算一个epoch\n",
    "    cfg.train['epoches_num'] = 1\n",
    "\n",
    "# 检验voc上训练的模型，在coco上的效果\n",
    "if cfg.mAP.save_voc_to_coco:\n",
    "    assert cfg.train.train == False\n",
    "    assert cfg.valid.valid == False\n",
    "    assert cfg.base.dataset == 'coco'\n",
    "    assert cfg.net.model_path is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999d42f",
   "metadata": {},
   "source": [
    "## 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed36d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:11.891971Z",
     "start_time": "2021-11-08T01:46:11.337550Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/root/jupyter_workhome/my_packages\") \n",
    "\n",
    "from tricks.epoches import epoches_n_try as epn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7beb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:13.609079Z",
     "start_time": "2021-11-08T01:46:11.893959Z"
    }
   },
   "outputs": [],
   "source": [
    "import yolo.encoder as en\n",
    "import yolo.load as load\n",
    "import yolo.aug as aug\n",
    "from yolo.backbone import resnet\n",
    "from yolo.loss import yolo_loss\n",
    "import yolo.mAP as mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf0e227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:13.617538Z",
     "start_time": "2021-11-08T01:46:13.611117Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b069538",
   "metadata": {},
   "source": [
    "## 创建子目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053216d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:13.662573Z",
     "start_time": "2021-11-08T01:46:13.621399Z"
    }
   },
   "outputs": [],
   "source": [
    "os.system('rm -rf %s' % cfg.tag)\n",
    "os.system('mkdir %s' % cfg.tag)\n",
    "\n",
    "os.system('mkdir %s/coco/' % cfg.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f28fd40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:13.681187Z",
     "start_time": "2021-11-08T01:46:13.665802Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存配置\n",
    "os.system('cp %s %s/' % (_cfg_path, cfg.tag))\n",
    "\n",
    "with open(cfg.tag+'/cfg_.json', 'w') as f:\n",
    "    json.dump(cfg.dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7826e7",
   "metadata": {},
   "source": [
    "## 适配python运行"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bae9bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-14T13:31:30.973691Z",
     "start_time": "2021-09-14T13:31:30.968189Z"
    }
   },
   "source": [
    "# python 执行时使用\n",
    "import logging\n",
    "LOG_FORMAT = \"%(asctime)s [%(levelname)8s] %(message)s\"\n",
    "DATE_FORMAT = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "logging.basicConfig(filename='./%s/log.txt' % cfg.tag,  # 会追加写入\n",
    "                    level=logging.INFO,\n",
    "                    format=LOG_FORMAT,\n",
    "                    datefmt=DATE_FORMAT)\n",
    "\n",
    "print = logging.info\n",
    "\n",
    "def tqdm(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d242f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:13.692882Z",
     "start_time": "2021-11-08T01:46:13.683214Z"
    }
   },
   "outputs": [],
   "source": [
    "print(cfg.dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3d87f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:13.711803Z",
     "start_time": "2021-11-08T01:46:13.694818Z"
    }
   },
   "outputs": [],
   "source": [
    "device = cfg.base.device\n",
    "\n",
    "device = device if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "\n",
    "print('device: ' + device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d9a90",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668469fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:13.720804Z",
     "start_time": "2021-11-08T01:46:13.713578Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.base.dataset == 'voc':\n",
    "    sys.path.append(\"/root/jupyter_workhome/dataset/VOCdevkit/\")\n",
    "\n",
    "    from VocDataset import get_dataset\n",
    "elif cfg.base.dataset == 'coco':\n",
    "    sys.path.append(\"/root/jupyter_workhome/dataset/coco/\")\n",
    "    \n",
    "    import CocoDataset as coco\n",
    "else:\n",
    "    raise RuntimeError('无法识别的数据集')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c0c24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:13.728134Z",
     "start_time": "2021-11-08T01:46:13.722564Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.base.dataset == 'voc':\n",
    "    keys = ['file_path', 'w', 'h', 'boxes_conner', 'labels_idx', 'filename']\n",
    "    \n",
    "    # todo 应该使用配置文件中的地址\n",
    "    if cfg.train.train:\n",
    "        train_data = get_dataset(['2007', '2012'], keys)\n",
    "        \n",
    "    if cfg.valid.valid or cfg.mAP.mAP:\n",
    "        test_data = get_dataset(['2007-test'], keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ff856",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.196783Z",
     "start_time": "2021-11-08T01:46:13.729915Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.base.dataset == 'coco':\n",
    "    keys = ['file_path', 'width', 'height', 'boxes_conner', 'category_id', 'file_name']\n",
    "    \n",
    "    if cfg.train.train:\n",
    "        train_data = coco.CocoDataset(cfg.base.dataset_uri.coco.train.an_paths, \n",
    "                                     cfg.base.dataset_uri.coco.train.img_paths, \n",
    "                                     keys)\n",
    "        \n",
    "    if cfg.valid.valid or cfg.mAP.mAP:\n",
    "        test_data = coco.CocoDataset(cfg.base.dataset_uri.coco.val.an_paths, \n",
    "                                     cfg.base.dataset_uri.coco.val.img_paths, \n",
    "                                     keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9cd75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.201179Z",
     "start_time": "2021-11-08T01:46:50.198632Z"
    }
   },
   "outputs": [],
   "source": [
    "def yolo_img_reader(file_path):\n",
    "    return cv2.imread(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f99547",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.207576Z",
     "start_time": "2021-11-08T01:46:50.202945Z"
    }
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "size_lst = [x*32 for x in range(10, 20)]\n",
    "cnt = 0\n",
    "idx = size_lst.index(cfg.net.image_size)\n",
    "\n",
    "\n",
    "def yolo_aug_train_multi_scale(img, boxes_corner, labels):\n",
    "    global cnt, idx\n",
    "    image_size = size_lst[idx]  # 从指定的image_size开始切换\n",
    "    cnt += 1\n",
    "    if cnt % (cfg.train.image_size_change_num*cfg.base.batch_size) == 0:  # 每10个batch，切换一次图片尺寸\n",
    "        idx = random.randint(0, len(size_lst)-1)\n",
    "    return aug.aug(img, boxes_corner, labels, is_train=True,\n",
    "                   aug_lst=cfg.train.aug_funcs,\n",
    "                   image_size=image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddb00f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.218988Z",
     "start_time": "2021-11-08T01:46:50.209257Z"
    }
   },
   "outputs": [],
   "source": [
    "def yolo_aug_train(img, boxes_corner, labels):\n",
    "    return aug.aug(img, boxes_corner, labels, is_train=True,\n",
    "                   aug_lst=cfg.train.aug_funcs,\n",
    "                   image_size=cfg.net.image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98474a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.226562Z",
     "start_time": "2021-11-08T01:46:50.220710Z"
    }
   },
   "outputs": [],
   "source": [
    "def yolo_aug_test(img, boxes_corner, labels):\n",
    "    return aug.aug(img, boxes_corner, labels, is_train=False,\n",
    "                   aug_lst=[],\n",
    "                   image_size=cfg.net.image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ca67f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.235101Z",
     "start_time": "2021-11-08T01:46:50.228296Z"
    }
   },
   "outputs": [],
   "source": [
    "def yolo_encoder(boxes, classes, S):\n",
    "    return en.encoder(boxes, classes,\n",
    "                      grid_num=S,  # 是按批变化的\n",
    "                      B=cfg.net.B,\n",
    "                      box_is_corner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f755acd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.244157Z",
     "start_time": "2021-11-08T01:46:50.236809Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.train.multi_scale:\n",
    "    detection_collate_train = load.DetectionCollate(yolo_img_reader,\n",
    "                                                    yolo_aug_train_multi_scale,\n",
    "                                                    yolo_encoder)\n",
    "else:\n",
    "    detection_collate_train = load.DetectionCollate(yolo_img_reader,\n",
    "                                                    yolo_aug_train,\n",
    "                                                    yolo_encoder)\n",
    "\n",
    "detection_collate_test = load.DetectionCollate(yolo_img_reader,\n",
    "                                               yolo_aug_test, \n",
    "                                               yolo_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3462c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.255450Z",
     "start_time": "2021-11-08T01:46:50.245940Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.train.train:\n",
    "    train_loader = DataLoader(\n",
    "        dataset=train_data,\n",
    "        batch_size=cfg.base.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=detection_collate_train\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d8354a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.268705Z",
     "start_time": "2021-11-08T01:46:50.264123Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.valid.valid or cfg.mAP.mAP:\n",
    "    test_loader = DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=cfg.base.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=detection_collate_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d97c619",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b64e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.799802Z",
     "start_time": "2021-11-08T01:46:50.272158Z"
    }
   },
   "outputs": [],
   "source": [
    "model = resnet(cfg.net.backbone,\n",
    "               pretrained=True,\n",
    "               out_channel=(4+1+cfg.net.C)*cfg.net.B)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65d855d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.832136Z",
     "start_time": "2021-11-08T01:46:50.801594Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3c4ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.852157Z",
     "start_time": "2021-11-08T01:46:50.833963Z"
    }
   },
   "outputs": [],
   "source": [
    "def load(model, model_path):\n",
    "    state_dict_pretrain = torch.load(model_path, map_location=device)\n",
    "    state_dict = model.state_dict()\n",
    "    \n",
    "    for k in state_dict_pretrain.keys():\n",
    "        if k in state_dict.keys() and (\n",
    "            state_dict[k].shape == state_dict_pretrain[k].shape\n",
    "        ):\n",
    "            # print(k)\n",
    "            state_dict[k] = state_dict_pretrain[k]\n",
    "        else:\n",
    "            print(k)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963cadba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.857915Z",
     "start_time": "2021-11-08T01:46:50.853815Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.net.model_path is not None:\n",
    "    print(\"load model from \"+ cfg.net.model_path)\n",
    "    # model.load_state_dict(torch.load(_model_path, map_location=device))\n",
    "    load(model, cfg.net.model_path)\n",
    "else:\n",
    "    print('train new model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c412e5",
   "metadata": {},
   "source": [
    "## 优化器&学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d782ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.863150Z",
     "start_time": "2021-11-08T01:46:50.859795Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch_lr = cfg.train.optimizer.epoch_lr\n",
    "_epoch_cnt, _lr = epoch_lr[0], epoch_lr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26766830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.878464Z",
     "start_time": "2021-11-08T01:46:50.865055Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.train.optimizer.use_adam:\n",
    "    print(\"use Adam optimizer\")\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=_lr[0],\n",
    "                                 weight_decay=cfg.train.optimizer.weight_decay)\n",
    "else:\n",
    "    print(\"use SGDm optimizer\")\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                lr=_lr[0],\n",
    "                                momentum=cfg.train.optimizer.momentum,\n",
    "                                weight_decay=cfg.train.optimizer.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18a0d9",
   "metadata": {},
   "source": [
    "## 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a5adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.896719Z",
     "start_time": "2021-11-08T01:46:50.880288Z"
    }
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "def save(model, loss, best_loss, tag, epoch, save_each=False):\n",
    "\n",
    "    if loss < best_loss:\n",
    "\n",
    "        ts = time.strftime(\"%Y%m%d-%H%M\", time.localtime())\n",
    "\n",
    "        with open('%s/best.txt' % tag, 'a') as f:\n",
    "            f.write('[%s] epoch:%03d loss:%.4f\\n' %\n",
    "                    (ts, epoch, loss))\n",
    "\n",
    "        if save_each:\n",
    "            path = f'./%s/model-%03d-%s-loss_%.4f.pth' % (tag, epoch, ts, loss)\n",
    "            print(path)\n",
    "            torch.save(model.state_dict(), path)\n",
    "\n",
    "        path = f'./%s/model-best.pth' % tag\n",
    "        print(path)\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "        return loss\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25908df5",
   "metadata": {},
   "source": [
    "## 训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219ea52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.908894Z",
     "start_time": "2021-11-08T01:46:50.900803Z"
    }
   },
   "outputs": [],
   "source": [
    "def avg_lst(x):\n",
    "    return round(sum(x) / len(x), cfg.base.csv_decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc83a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.921117Z",
     "start_time": "2021-11-08T01:46:50.910580Z"
    }
   },
   "outputs": [],
   "source": [
    "def str_startswith(s, s_list):\n",
    "    for ss in s_list:\n",
    "        if s.startswith(ss):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, model_lock_names: list, requires_grad=False):\n",
    "    \"\"\"\n",
    "    names  在这个列表中的参数，不会被设置\n",
    "    \"\"\"\n",
    "    for name, param in model.named_parameters():\n",
    "        if str_startswith(name, model_lock_names):\n",
    "            print(name)\n",
    "            param.requires_grad = not requires_grad\n",
    "        else:\n",
    "            param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b469e65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.932659Z",
     "start_time": "2021-11-08T01:46:50.925406Z"
    }
   },
   "outputs": [],
   "source": [
    "def lock_shift(model, epoch):\n",
    "    for k, v in enumerate(cfg.net.model_lock_epoch):\n",
    "        if epoch == v:\n",
    "            print('shift model lock at epoch %d with %s' % (v, str(cfg.net.model_lock_names[k])))\n",
    "            set_parameter_requires_grad(model, model_lock_names=cfg.net.model_lock_names[k])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd9c81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.983395Z",
     "start_time": "2021-11-08T01:46:50.977385Z"
    }
   },
   "outputs": [],
   "source": [
    "def lr_shift(epoch):\n",
    "    for k, v in enumerate(_epoch_cnt):\n",
    "        if epoch < v:\n",
    "            return _lr[k]\n",
    "\n",
    "    return _lr[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grad(optimizer):\n",
    "    for k, p in enumerate(optimizer.param_groups[0]['params']):\n",
    "        if p.grad is not None and p.grad.isnan().sum().item() > 0:\n",
    "            print(k, p.shape)\n",
    "            # print(p)\n",
    "            # print(p.grad)\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d05a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warm_up(global_step_num, init_lr, end_lr, step_num):\n",
    "    assert init_lr < end_lr\n",
    "    if global_step_num > step_num:\n",
    "        # 返回None，这样后续就不再更新\n",
    "        return None\n",
    "    else:\n",
    "        return init_lr + (end_lr - init_lr)*global_step_num/step_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1f412",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.956943Z",
     "start_time": "2021-11-08T01:46:50.934432Z"
    }
   },
   "outputs": [],
   "source": [
    "_init_batch_num = cfg.loss.init_iter_num // cfg.base.batch_size\n",
    "\n",
    "\n",
    "def train_valid(epoch, model, loader, mode):\n",
    "    if mode == 'train':\n",
    "        model.train()\n",
    "\n",
    "        # 更新学习率\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr_shift(epoch)\n",
    "\n",
    "    else:\n",
    "        model.eval()  # 只对dropout 和BN有效，不会关闭梯度计算的\n",
    "\n",
    "    loss_, loss_1, loss_2, loss_3, loss_4, loss_5, loss_6 = [], [], [], [], [], [], []\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    # 一个epoch的batch数量\n",
    "    batches_num = len(loader)\n",
    "\n",
    "    for k, (imgs, target, _, img_names, wh) in enumerate(tqdm(loader)):\n",
    "\n",
    "        imgs_ = imgs.to(device)\n",
    "        target_ = target.to(device)\n",
    "\n",
    "        # 固定模型的一部分，加快训练速度====================\n",
    "        if mode == 'train' and cfg.net.model_lock:\n",
    "            if k == 0:\n",
    "                lock_shift(model, epoch)\n",
    "\n",
    "        # 当下是第几次计算(全局的)\n",
    "        if epoch >= 0:\n",
    "            global_step_num = batches_num * epoch + k\n",
    "        else:\n",
    "            global_step_num = -1\n",
    "\n",
    "        # 学习率的warm-up====================\n",
    "        if mode == 'train' and cfg.train.optimizer.warm_up.warm_up:\n",
    "            new_lr = warm_up(global_step_num,\n",
    "                             cfg.train.optimizer.warm_up.init_lr,\n",
    "                             cfg.train.optimizer.warm_up.end_lr,\n",
    "                             cfg.train.optimizer.warm_up.step_num)\n",
    "            if new_lr is not None:\n",
    "                # 更新学习率\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = new_lr\n",
    "\n",
    "        # 模型计算=======================================\n",
    "        pred = model(imgs_)\n",
    "\n",
    "        # 计算loss======================================\n",
    "        if cfg.mAP.save_voc_to_coco:  # 因为边框的计算需要\n",
    "            __anchors_wh = cfg.anchor.voc\n",
    "        else:\n",
    "            __anchors_wh = cfg.anchor.wh\n",
    "\n",
    "        l_t = yolo_loss(pred, target_, global_step_num,\n",
    "                        B=cfg.net.B, C=cfg.net.C,\n",
    "                        anchor=cfg.net.anchor,\n",
    "                        # v1\n",
    "                        wh_sqrt=cfg.loss.wh_sqrt,\n",
    "                        # v2\n",
    "                        anchors_wh=__anchors_wh,\n",
    "                        anchors_calc_iou=cfg.loss.anchors_calc_iou,\n",
    "                        init_batch_num=_init_batch_num,\n",
    "                        # v3\n",
    "                        conf_target_iou=cfg.loss.conf_target_iou,\n",
    "                        conf_bce=cfg.loss.conf_bce,\n",
    "                        cls_ce=cfg.loss.cls_ce,\n",
    "                        focus_on_small=cfg.loss.focus_on_small)\n",
    "\n",
    "        l = (l_t * torch.tensor(cfg.loss.coefficients, device=device)).sum()\n",
    "\n",
    "        # 反向传播======================================\n",
    "        if mode == 'train':\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute the gradients for parameters.\n",
    "            l.backward()\n",
    "\n",
    "            # 检查梯度是否有nan\n",
    "            if check_grad(optimizer):\n",
    "                # Update the parameters with computed gradients.\n",
    "                optimizer.step()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        loss_.append(l.item())\n",
    "        loss_1.append(l_t[0].item())\n",
    "        loss_2.append(l_t[1].item())\n",
    "        loss_3.append(l_t[2].item())\n",
    "        loss_4.append(l_t[3].item())\n",
    "        loss_5.append(l_t[4].item())\n",
    "        loss_6.append(l_t[5].item())\n",
    "\n",
    "        n = cfg.base.batch_n_print\n",
    "        if k != 0 and k % n == 0:\n",
    "            print(f'batches[%5d/%5d]: %.4f (%.4f %.4f %.4f %.4f %.4f %.4f)' % (\n",
    "                k, len(loader),\n",
    "                avg_lst(loss_[-n:]),\n",
    "                avg_lst(loss_1[-n:]),\n",
    "                avg_lst(loss_2[-n:]),\n",
    "                avg_lst(loss_3[-n:]),\n",
    "                avg_lst(loss_4[-n:]),\n",
    "                avg_lst(loss_5[-n:]),\n",
    "                avg_lst(loss_6[-n:])))\n",
    "\n",
    "        del imgs, imgs_\n",
    "        del target, target_\n",
    "        del pred, l_t\n",
    "\n",
    "    d.update(\n",
    "        {\n",
    "            mode + \"_loss\": avg_lst(loss_),\n",
    "            mode + \"_loss_1\": avg_lst(loss_1),\n",
    "            mode + \"_loss_2\": avg_lst(loss_2),\n",
    "            mode + \"_loss_3\": avg_lst(loss_3),\n",
    "            mode + \"_loss_4\": avg_lst(loss_4),\n",
    "            mode + \"_loss_5\": avg_lst(loss_5),\n",
    "            mode + \"_loss_6\": avg_lst(loss_6)\n",
    "        }\n",
    "    )\n",
    "    # 为了降低显存占用\n",
    "    # del imgs, target, pred, l_t\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bceaf",
   "metadata": {},
   "source": [
    "## 计算mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191f25d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.975335Z",
     "start_time": "2021-11-08T01:46:50.959114Z"
    }
   },
   "outputs": [],
   "source": [
    "best_mAP = -1\n",
    "\n",
    "\n",
    "def calc_mAP(model, test_loader, tag, save_coco, epoch):\n",
    "    global best_mAP\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    preds_dict = None\n",
    "\n",
    "    for k, (imgs, _1, _2, img_names, wh) in enumerate(tqdm(test_loader)):\n",
    "\n",
    "        imgs = imgs.to(device)\n",
    "        wh = wh.to(device)\n",
    "\n",
    "        pred = model(imgs)\n",
    "\n",
    "        if cfg.mAP.save_voc_to_coco:\n",
    "            __anchors_wh = cfg.anchor.voc\n",
    "        else:\n",
    "            __anchors_wh = cfg.anchor.wh\n",
    "\n",
    "        preds_dict = en.flat_decoder(pred, img_names, preds_dict, wh,\n",
    "                                     c_threshold=cfg.mAP.conf_threshold,\n",
    "                                     iou_threshold=cfg.mAP.NMS_threshold,\n",
    "                                     B=cfg.net.B, cls_num=cfg.net.C,\n",
    "                                     anchor=cfg.net.anchor,\n",
    "                                     anchors_wh=__anchors_wh,\n",
    "                                     max_len=cfg.mAP.max_len)\n",
    "    if cfg.base.dataset == 'voc':\n",
    "        mAp_dict = mAP.mAP_2007test(preds_dict, use_target_abs=True)\n",
    "\n",
    "    if cfg.base.dataset == 'coco':\n",
    "        if cfg.mAP.save_voc_to_coco:\n",
    "            d = {}\n",
    "            for k in preds_dict:\n",
    "                # 将voc的分类id，映射成为coco的分类id\n",
    "                d[coco.voc20_to_coco80_minus1[k]] = preds_dict[k]\n",
    "            preds_dict = d\n",
    "\n",
    "        # 计算mAP\n",
    "        # mAp_dict = mAP.mAP_coco_val2017(preds_dict, use_target_abs=True)\n",
    "        target_coco = mAP.load_coco(test_data, use_target_abs=True)\n",
    "        # mAp_dict = mAP.mAP_coco(preds_dict, target_coco)\n",
    "        mAp_dict = mAP.mAP(preds_dict, target_coco,\n",
    "                           threshold=0.5, CLASSES=coco.COCO_CLASSES)\n",
    "        \n",
    "        if cfg.mAP.save_voc_to_coco:\n",
    "            # 只使用voc的20个类计算mAP\n",
    "            ap_sum = 0\n",
    "            for i in range(20):\n",
    "                cls_idx_coco = coco.voc20_to_coco80_minus1[i]\n",
    "                cls_coco = coco.COCO_CLASSES[cls_idx_coco]\n",
    "                ap = mAp_dict[cls_coco]\n",
    "                # 因为预测不到，AP可能就为-1\n",
    "                ap = ap if ap >=0 else 0\n",
    "                ap_sum += ap\n",
    "\n",
    "            mAp_dict['mAP'] = ap_sum/20\n",
    "\n",
    "    mAp_dict = {\n",
    "        'AP_'+k: round(mAp_dict[k], cfg.base.csv_decimal) for k in mAp_dict}\n",
    "\n",
    "    _mAP = mAp_dict['AP_mAP']\n",
    "\n",
    "    path_lst = []\n",
    "\n",
    "    if save_coco and _mAP > cfg.mAP.save_coco_when_gt:  # 要不然太大了\n",
    "        # 保存为coco格式\n",
    "        path = '%s/coco/coco-mAP%.4f-%d-%s.json' % (tag,\n",
    "                                                    _mAP,\n",
    "                                                    epoch,\n",
    "                                                    time.strftime(\n",
    "                                                        \"%Y%m%d-%H%M\", time.localtime())\n",
    "                                                    )\n",
    "        print('save to ' + path)\n",
    "        path_lst.append(path)\n",
    "\n",
    "    if _mAP > best_mAP:\n",
    "        path = '%s/coco/coco-best.json' % tag\n",
    "        print('save to ' + path)\n",
    "        with open('%s/coco/best.txt' % tag, 'a') as f:\n",
    "            f.write('[%s] epoch:%03d mAP:%.4f\\n' % (time.strftime(\n",
    "                \"%Y%m%d-%H%M\", time.localtime()), epoch, _mAP))\n",
    "\n",
    "        path_lst.append(path)\n",
    "\n",
    "        best_mAP = _mAP\n",
    "\n",
    "    if len(path_lst) > 0:\n",
    "        # 将coco的id从80映射到91\n",
    "        if cfg.base.dataset == 'coco':\n",
    "            d = {}\n",
    "            for cls_idx in preds_dict:\n",
    "                cls_idx_91 = coco.coco80_minus1_to_91[cls_idx]\n",
    "                d[cls_idx_91] = preds_dict[cls_idx]\n",
    "            preds_dict = d\n",
    "        \n",
    "        # 保存coco格式的计算结果\n",
    "        mAP.save_as_coco(preds_dict,\n",
    "                         path_lst,\n",
    "                         lambda x: x,\n",
    "                         lambda x: int(x.split('.')[0]))\n",
    "\n",
    "        # 这里偷懒一下，直接保存对应的模型\n",
    "        if cfg.mAP.save_best_mAP_model:\n",
    "            path = f'./%s/coco/model-best-mAP.pth' % tag\n",
    "            torch.save(model.state_dict(), path)\n",
    "\n",
    "    # 为了降低显存占用\n",
    "    del imgs, _1, _2, wh, pred, preds_dict\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    return mAp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1941b",
   "metadata": {},
   "source": [
    "## train函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5dfa7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:46:50.994767Z",
     "start_time": "2021-11-08T01:46:50.985410Z"
    }
   },
   "outputs": [],
   "source": [
    "best_loss = 9999\n",
    "\n",
    "@epn(cfg.train.epoches_num,\n",
    "     func_table_path='./%s/func.csv' % cfg.tag,\n",
    "     mon_table_path='./%s/monitor.csv' % cfg.tag)\n",
    "def train(epoch, epoch_num):\n",
    "    global best_loss\n",
    "\n",
    "    d = {'lr': optimizer.param_groups[0]['lr']}\n",
    "    print('lr: %f' % d['lr'])\n",
    "\n",
    "    if cfg.train.train:\n",
    "        print(f'[ Train | {epoch + 1:03d}/{epoch_num:03d} ] start')\n",
    "        d1 = train_valid(epoch, model, train_loader, 'train')\n",
    "        train_loss = d1['train_loss']\n",
    "        d.update(d1)\n",
    "        # Print the information.\n",
    "        print(f\"[ Train | {epoch + 1:03d}/{epoch_num:03d} ] loss = {d1['train_loss']:.4f} -> {d1['train_loss_1']:.4f} {d1['train_loss_2']:.4f} {d1['train_loss_3']:.4f} {d1['train_loss_4']:.4f} {d1['train_loss_5']:.4f} {d1['train_loss_6']:.4f}\")\n",
    "\n",
    "    # val & test\n",
    "    with torch.no_grad():\n",
    "        if cfg.valid.valid:\n",
    "            print(f'[ Valid | {epoch + 1:03d}/{epoch_num:03d} ] start')\n",
    "            d2 = train_valid(-1, model, test_loader, 'val')\n",
    "            val_loss = d2['val_loss']\n",
    "            # Print the information.\n",
    "            d.update(d2)\n",
    "            if cfg.valid.save_best_loss_model:\n",
    "                print('try save model')\n",
    "                best_loss = save(model, val_loss, best_loss, cfg.tag, epoch)\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{epoch_num:03d} ] loss = {d2['val_loss']:.4f} -> {d2['val_loss_1']:.4f} {d2['val_loss_2']:.4f} {d2['val_loss_3']:.4f} {d2['val_loss_4']:.4f} {d2['val_loss_5']:.4f} {d2['val_loss_6']:.4f}\")\n",
    "\n",
    "        \n",
    "        # 计算mAP\n",
    "        if cfg.mAP.mAP:\n",
    "            print(f'[  mAP  | {epoch + 1:03d}/{epoch_num:03d} ] start')\n",
    "            d3 = calc_mAP(model, test_loader, cfg.tag, cfg.mAP.save_coco, epoch)\n",
    "            d.update(d3)\n",
    "            print(f\"[  mAP  | {epoch + 1:03d}/{epoch_num:03d} ] mAP: %s\" % str(d3))\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2dd90e",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026d2df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:47:10.338149Z",
     "start_time": "2021-11-08T01:46:50.996759Z"
    }
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d33ddf",
   "metadata": {},
   "source": [
    "## 重命名子目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f2f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T01:47:10.347128Z",
     "start_time": "2021-11-08T01:46:11.451Z"
    }
   },
   "outputs": [],
   "source": [
    "if cfg.base.rename_dir:\n",
    "    ts = time.strftime(\"%Y%m%d_%H%M\", time.localtime())\n",
    "    path = '%s-%s' % (cfg.tag, ts)\n",
    "\n",
    "    os.system('mv %s %s' % (cfg.tag, path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "672px",
    "left": "1177px",
    "right": "20px",
    "top": "116px",
    "width": "598px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
